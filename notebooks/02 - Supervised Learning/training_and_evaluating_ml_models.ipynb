{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b6d7b6-698e-4ea2-b8e9-bad6f279fcfe",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/schwallergroup/ai4chem_course/blob/scikit_learn/notebooks/02%20-%20Supervised%20Learning/training_and_evaluating_ml_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ee09d-524b-4f90-ac5c-cc37187ba4c4",
   "metadata": {},
   "source": [
    "# Week 2 tutorial - AI 4 Chemistry\n",
    "\n",
    "## Index:\n",
    "\n",
    "- Regression\n",
    "    - scikit-learn\n",
    "    - \n",
    "- Classification\n",
    "\n",
    "\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d3c35",
   "metadata": {},
   "source": [
    "# 0. Software\n",
    "### Scikit-learn\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. It is widely used in industry and academia, and a wealth of tutorials and code snippets are available online.\n",
    "We will learn to use scikit-learn to do machine learning work. You can also browse the scikit-learn [user guide](https://scikit-learn.org/stable/user_guide.html) and [tutorials](https://scikit-learn.org/stable/tutorial/index.html) for additional details.\n",
    "### Essential Libraries and Tools \n",
    "Scikit-learn depends on two other Python packages, NumPy and SciPy. For plotting and interactive development, you should also install matplotlib, IPython, and the Jupyter Notebook.\n",
    "- **NumPy** is one of the fundamental packages for scientific computing in Python. It contains functionality for multidimensional arrays, high-level mathematical functions such as linear algebra operations and the Fourier transform, and pseudorandom number generators. In scikit-learn, the NumPy array is the fundamental data structure. scikit-learn takes in data in the form of NumPy arrays. Any data you’re using will have to be converted to a NumPy array.\n",
    "- **SciPy** is a collection of functions for scientific computing in Python. It provides, among other functionality, advanced linear algebra routines, mathematical function optimization, signal processing, special mathematical functions, and statistical distributions. scikit-learn draws from SciPy’s collection of functions for implementing its algorithms.\n",
    "- **Matplotlib** is the primary scientific plotting library in Python. It provides functions for making publication-quality visualizations such as line charts, histograms, scatter plots, and so on.\n",
    "- **Pandas** Python library for data wrangling and analysis. It is built around a data structure called the DataFrame that is similar to an Excel spreadsheet. It can ingest from a great variety of file formats and databases, like SQL, Excel files, and comma-separated values (CSV) files.\n",
    "\n",
    "### XGBoost\n",
    "XGBoost (eXtreme Gradient Boosting) is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. You can also browse the [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/) for additional details.\n",
    "\n",
    "### DeepChem\n",
    "DeepChem is a high quality open-source toolchain that democratizes the use of deep-learning in chemistry, biology and materials science. It also provides various tools for dataset loader, splitters, molecular featurization, model construction and hyperparameter tuning. You can also browse the [DeepChem Ducumentation](https://deepchem.readthedocs.io/en/latest/) for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbf541",
   "metadata": {},
   "source": [
    "We will first install the required libraries. We also need `RDKit` library to process and analyze molecules, like calculating molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4688b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib scikit-learn pandas rdkit xgboost deepchem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ae06f",
   "metadata": {},
   "source": [
    "# 1. Introduction to Machine learning\n",
    "Machine learning (ML) is a field of inquiry devoted to understanding and building methods that \"learn\" – that is, methods that leverage data to improve performance on some set of tasks. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://s3.ap-southeast-1.amazonaws.com/files-scs-prod/public%2Fimages%2F1605842918803-AI+vs+ML+vs+DL.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n",
    "- **Supervised learning**: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\n",
    "- **Unsupervised learning**: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\n",
    "- **Reinforcement learning**: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximize.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://starship-knowledge.com/wp-content/uploads/2021/01/unsupervised_supervised_reinforcement.jpeg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba2fc2",
   "metadata": {},
   "source": [
    "# 2. Supervised learning\n",
    "Two major types of supervised machine learning problems:\n",
    "- **Classification** task is to predict a class label, which is a choice from a predefined list of possibilities. For example, to determine whether the photo is a dog, a cat or a rabbit.\n",
    "- **Regression** task is to predict a continuous number, or a floating-point number in programming terms (or real number in mathematical terms), like predicting a person’s annual income from their education, their age, and where they live.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*xs6Jr4iAPvoqszF9JgDWOA.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "## Common algorithms\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Linear Models\n",
    "- Support Vector Machines\n",
    "- Decision Trees\n",
    "- Ensembles of Decision Trees\n",
    "  - Random forests\n",
    "  - Gradient boosting machines\n",
    "\n",
    "We can use `scikit-learn` to create ML models of different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3) # instantiate the model and set the number of neighbors to consider to 3\n",
    "\n",
    "# k-NN regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=3) # instantiate the model and set the number of neighbors to consider to 3\n",
    "\n",
    "# linear regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# decision tree classifier & regressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "# random forest classifier & regressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "ranf_clf = RandomForestClassifier(n_estimators=10)  # using 10 trees\n",
    "ranf_reg = RandomForestRegressor(n_estimators=10)  # using 10 trees\n",
    "\n",
    "# XGBoost classifier & regressor\n",
    "# from xgboost import XGBClassifier, XGBRegressor\n",
    "# bst_clf = XGBClassifier(n_estimators=10)  # using 10 trees\n",
    "# bst_reg = XGBRegressor(n_estimators=10)  # using 10 trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a633f2c",
   "metadata": {},
   "source": [
    "## Common steps\n",
    "1. Prepare data & split data\n",
    "2. Choose the model\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "5. Use the model\n",
    "\n",
    "Below is a simple example to show basic steps of machine learning. Our goal is to build a machine learning model that can learn from the measurements (the length and width of the petals and the length and width of the sepals) of these irises whose species is known, so that we can predict the species for a new iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f64625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "# Get the information of this dataset\n",
    "print(iris_dataset['DESCR'][:193] + \"\\n...\\n\")\n",
    "print(\"Shape of data:\", iris_dataset['data'].shape)\n",
    "print(\"Shape of target:\", iris_dataset['target'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d311b",
   "metadata": {},
   "source": [
    "Below is a simple example to show basic steps of machine learning. Our goal is to build a machine learning model that can learn from chemical structures (as encoded in SMILES strings) to predict water solubility. We will use ESOL dataset from [MoleculeNet](https://doi.org/10.1039/C7SC02664A) to train the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8b2f1",
   "metadata": {},
   "source": [
    "Load dataset & show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset from a CSV file\n",
    "esol_df = pd.read_csv('../data/esol.csv')\n",
    "esol_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e9894",
   "metadata": {},
   "source": [
    "The original dataset contains 2 columns, where the `smiles` column represents the SMILES strings of the solute molecules. The column `log solubility (mol/L)` represents the solubility of molecules in water, which is the predicted target of our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = esol_df['smiles'].values\n",
    "y = esol_df['log solubility (mol/L)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343779ed",
   "metadata": {},
   "source": [
    "We need to convert the SMILES strings of molecules into numerical values that can be used as input to the ML models. We can calculate molecular descirptors from SMILES strings by some software like `RDKit`, `DeepChem` and [Mordred](https://github.com/mordred-descriptor/mordred). Here we use DeepChem [Featurizers](https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html) to compute molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5961b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we use molecular descriptors from RDKit, like molecular weight, number of valence electrons, maximum and minimum partial charge, etc.\n",
    "from deepchem.feat import RDKitDescriptors\n",
    "featurizer = RDKitDescriptors()\n",
    "features = featurizer.featurize(smiles)\n",
    "print(\"Number of molecular descriptors:\", features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07fca6d",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f23025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Min-Max Normalization of features\n",
    "fea_max = features.max(axis=0)\n",
    "fea_min = features.min(axis=0)\n",
    "fea_norm = (features - fea_min) / (fea_max - fea_min)\n",
    "\n",
    "# Check if normalized features contain invalid values\n",
    "contain_nan = (True in np.isnan(fea_norm))\n",
    "if contain_nan:\n",
    "    print('Our normalized features contain invalid values, please delete them before model training!')\n",
    "    fea_norm = fea_norm[:, ~np.isnan(fea_norm).any(axis=0)]\n",
    "    print('Dropping of columns containing invalid values has been completed.')\n",
    "else:\n",
    "    print('Our normalized features do not contain invalid values.')\n",
    "print(\"Shape of molecular descriptors after data preprocessing:\", fea_norm.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138076f4",
   "metadata": {},
   "source": [
    "Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8675b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = fea_norm\n",
    "# train data size : test data size = 0.8 : 0.2\n",
    "# fixed seed using the random_state parameter, so it always has the same split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d369a",
   "metadata": {},
   "source": [
    "Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b94772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regressor, and the criterion is mean squared error (MSE)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "ranf_reg = RandomForestRegressor(n_estimators=50, random_state=0)  # using 50 trees and seed=0\n",
    "\n",
    "# XGBoost regressor\n",
    "from xgboost import XGBRegressor\n",
    "bst_reg = XGBRegressor(n_estimators=50, random_state=0)  # using 50 trees and seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b6e04",
   "metadata": {},
   "source": [
    "Train and evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b21ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for random forests\n",
    "ranf_reg.fit(X_train, y_train)  # train the model\n",
    "ranf_train_mse = ranf_reg.score(X_train, y_train)\n",
    "ranf_test_mse = ranf_reg.score(X_test, y_test)\n",
    "ranf_train_rmse = ranf_train_mse ** 0.5\n",
    "ranf_test_rmse = ranf_test_mse ** 0.5\n",
    "print('Random forests performance:')\n",
    "print('RMSE on train set: {:.3f}, and test set: {:.3f}.\\n'.format(ranf_train_rmse, ranf_test_rmse))\n",
    "\n",
    "# for XGBoost\n",
    "bst_reg.fit(X_train, y_train)  # train the model\n",
    "y_pred_train = bst_reg.predict(X_train)\n",
    "y_pred_test = bst_reg.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "bst_train_mse = mean_squared_error(y_pred_train, y_train)\n",
    "bst_test_mse = mean_squared_error(y_pred_test, y_test)\n",
    "bst_train_rmse = bst_train_mse ** 0.5\n",
    "bst_test_rmse = bst_test_mse ** 0.5\n",
    "print('XGBoost performance:')\n",
    "print('RMSE on train set: {:.3f}, and test set: {:.3f}.'.format(bst_train_rmse, bst_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c715f",
   "metadata": {},
   "source": [
    "The results show that the RMSE value of XGBoost on the test set is smaller, indicating that the XGBoost is more accurate than random forests on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5622c1-38ec-4e45-b6bb-2547a31408f6",
   "metadata": {},
   "source": [
    "# Introduction to traditional ML.\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "Training a model to take inputs X and return output y.\n",
    "\n",
    "As you have seen in class, for this type of learning, we have two variants:\n",
    "\n",
    "- Classification\n",
    "- Regression\n",
    "\n",
    "Linear regression is one example of suppervised learning for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369daf7-90c9-4b68-abb9-ac5d80330dd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression\n",
    "\n",
    "### TODO: Improve this introduction based on the ESOL paper, why is solub. prediction important?\n",
    "\n",
    "One problem in both academic and industrial chemistry is predicting solubility. For instance we might know that some molecule has good potential as a ligand for some relevant reaction, however when you synthesize it, you realize it's not soluble under your already optimized reaction conditions! 😥\n",
    "\n",
    "It would be extremely useful to know the solubility of my molecule, **before I even try to synthesize it**!\n",
    "\n",
    "---\n",
    "\n",
    "In this task we will try to solve this using supervised learning. In particular, we will train a regression model using the very convenient [scikit-learn](https://www.kaggle.com/competitions/MerckActivity/data) Python library, to predict solubility based on some molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b43b84-aaf6-48cf-893f-3e42267846bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's start with loading the data, visualizing some molecules and their solubility\n",
    "# Let's also see some stats. e.g. size of dataset, distribution of solubility, etc.\n",
    "\n",
    "# TODO: Generate features\n",
    "# TODO do a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcce8c9-6a29-424b-af64-ed669a5c0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's give an introduction to scikit learn by doing a simple linear regression and see the results.\n",
    "# TODO Introduce sckit-learn, and use a RF model for this.\n",
    "import tempfile\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_regression\n",
    "cache_path = tempfile.gettempdir()  # we use a temporary folder here\n",
    "X, _ = make_regression(n_samples=50, n_features=25, random_state=0)\n",
    "estimator = make_pipeline(\n",
    "    KNeighborsTransformer(mode='distance'),\n",
    "    Isomap(n_components=3, metric='precomputed'),\n",
    "    memory=cache_path)\n",
    "X_embedded = estimator.fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbad9e-a85a-4e1d-a9fa-39aaa5b31bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's train another model (this can be an excercise)\n",
    "\n",
    "# EXERCISE: Implement random forest and and XGBoost models using scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8ae8d-2a3d-4634-aeb6-3e52df6956fb",
   "metadata": {},
   "source": [
    "# As we see, there are many possible models we can use for this task. But which one is better?\n",
    "\n",
    "In addition, each model has a set of hyperparameters that we need to tune ourselves. How do we select them?\n",
    "\n",
    "This is an important part of machine learning! What we want to know is: What is the best combination of model + model hyperparameters for our task? \n",
    "As you've seen in the course, common strategies to evaluate and compare model's performance include:\n",
    "\n",
    "- Splitting dataset in train/validation/test.\n",
    "- Doing cross-validation for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76a7d2-8e3a-466d-9dad-f83681ede02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data in train/valid/test\n",
    "\n",
    "# Retrain the models on the train set, and compare them using the validation set.\n",
    "\n",
    "# What model is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494286d-5d26-4aa7-9b55-13de0ce0446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's do cross-validation\n",
    "\n",
    "# Optimize the hyperparameters for XGBoost, and again compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9494e4-f0bb-441d-981b-65da64b96254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finally, compare all models on the test set.\n",
    "# Explain that test set should never be seen by models.\n",
    "# This is all completely new data so we know how it would work in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d4f4b-d19f-43ba-94f8-a6751a55ca66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c0988-ae0f-4f19-8de6-d4d4925f493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8866de4-74b2-4f8e-b619-ed8aace169c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ba8f80-fd59-44f7-beb5-31387ec376d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Classification\n",
    "\n",
    "We now turn our attention towards the other type of supervised learning: classification.\n",
    "\n",
    "Many questions in chemistry can be framed as a classification task: \n",
    "\n",
    "- Will this molecule act as a nucleophile or electrophile in my reaction?\n",
    "- What is the smell of this substance? (fruity, citrus, sweet, ...)\n",
    "\n",
    "But in this tutorial we will try to respond:\n",
    "\n",
    "<div>\n",
    "<img src=\"img/is_this_toxic.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## For this, we need data. [MoleculeNet](https://moleculenet.org/datasets-1) provides several datasets, and we'll work with `ClinTox` for prediction of toxicity.\n",
    "\n",
    "ClinTox is a dataset containing `qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons`.\n",
    "\n",
    "Let's see if one of our models can tell what molecules are toxic!\n",
    "\n",
    "This is super useful for instance in drug discovery, where we want to know if a molecule has potential as a drug, **even before we synthesize it**.\n",
    "\n",
    "The steps we follow are similar to those we saw for regression:\n",
    "\n",
    "1. Prepare & split data\n",
    "2. Choose a model\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "5. Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83e8dd-2277-42c6-b99a-2eec6b0e44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load clintox data from the data directory and see what it contains\n",
    "df_toxicity = pd.read_csv(\"data/clintox.csv\")\n",
    "print(df_toxicity.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cfd3d-5090-4a34-8fde-c7e6f157e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Visualize some of the molecules of this dataset\n",
    "n=6\n",
    "smiles = df_toxicity.smiles.sample(n).values\n",
    "legend = df_toxicity.CT_TOX.sample(n).values\n",
    "molecs = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "Draw.MolsToGridImage(\n",
    "    molecs,\n",
    "    subImgSize=(600,300),\n",
    "    legends=[\"Toxic\" if i==1 else \"Non toxic\" for i in legend]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d934d7-2b65-436f-a02f-f7115c6c977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many toxic molecules are in the dataset?\n",
    "counts = df_toxicity[\"CT_TOX\"].value_counts()\n",
    "\n",
    "print(f\"The dataset contains {counts.sum()} molecules; {counts.iloc[1]} of them are toxic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7330eb2-1955-4f1d-92a6-7a094ad50333",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now, we will calculate some molecular descriptors using the [mordred package](http://mordred-descriptor.github.io/documentation/master/descriptors.html).\n",
    "\n",
    "This can take a while (how much??), you can use this time to explore a bit the more than 1600 descriptors from mordred!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf18155-356f-4305-9727-1ebf3f6d90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from deepchem.feat import MordredDescriptors\n",
    "\n",
    "featurizer = MordredDescriptors(ignore_3D=True)\n",
    "features = featurizer.featurize(smiles)\n",
    "print(\"Number of molecular descriptors:\", features.shape[1])\n",
    "\n",
    "X = df_toxicity.smiles.apply(lambda x: featurizer.featurize(x))\n",
    "y = df_toxicity.CT_TOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efa0dd-395a-409f-819d-4b41a14f0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you see from the warnings, mordred couldn't calculate features for a few molecules (but don't worry!)\n",
    "# Remove these molecules from the dataset\n",
    "\n",
    "X =mols\n",
    "y = df_toxicity.CT_TOX\n",
    "\n",
    "missing = X.apply(lambda x: x.shape == (1, features.shape[1]))\n",
    "\n",
    "print(f\"Dropping {(~missing).sum()} molecules that couldn't be featurized.\")\n",
    "X = X[missing].values\n",
    "y = y[missing].values\n",
    "\n",
    "X = np.concatenate(X)\n",
    "\n",
    "# Also, some features contain NaN values (not a number). Let's remove them.\n",
    "nan_feats = np.isnan(X).any(axis=0)\n",
    "print(f\"Dropping {nan_feats.sum()} features as they contain NaN values.\")\n",
    "X = X[:,~nan_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0319fe-73ae-4500-9889-59f14949a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Which molecules couldn't be featurized? Why?\n",
    "# Using code from above, visualize the faulty molecules.\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920f04b-5cb3-4057-bac5-e7ed8eca57dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting.\n",
    "\n",
    "For this exercise, we will do a simple train/test split as we will not optimize hyperparameters. (Maybe bonus exercise here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c46051-b3dc-4931-91ed-7904dcc1d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train data size : test data size = 0.8 : 0.2\n",
    "# fixed seed using the random_state parameter, so it always has the same split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.6,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Train set size is {X_train.shape[0]} rows, test set size is {X_test.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de382e-50de-4211-911a-08ed09bfb4a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "Let's train a Random Forest Classification from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09c804-41d8-40fb-985a-625e83640efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rf_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13029e24-4b8c-45c5-9bd9-be41479dba50",
   "metadata": {},
   "source": [
    "### Exercise: You have already seen some cool classification algorithms in class.\n",
    "\n",
    "In this exercise, your task is to implement your 2 favorite algorithms using sklearn. \n",
    "\n",
    "Recommendations: \n",
    "\n",
    "- You can choose from [Logistic Regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#classification), [Gradient Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting), or any other from the [sklearn documentation](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "- Give a different name to each model. For instance, our Random Forest model is `rf_clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ec970-200c-4d22-bd40-e2e791faa004",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf09c91-bdcc-450b-ac7e-0799111fb453",
   "metadata": {},
   "source": [
    "## After training these models, let's see which one worked best! \n",
    "\n",
    "For the evaluation of classification models, **we use different metrics** than evaluation of regression models. \\\n",
    "You can read more about each metric [here](https://scikit-learn.org/stable/modules/model_evaluation.html), but for this tutorial we will use [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [ROC-AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score), and [F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121851be-f4b9-4ac0-83e0-269ecff3de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate our models \n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Exercise: Use your models to predict the toxicity of the molecules on the test set.\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67108633-40d3-4cae-b45d-6f5853254dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Let's calculate accuracy_score for all our models\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy of Random Forest Classifier is {acc_rf:.3f}\")\n",
    "\n",
    "# Exercise: Calculate the 3 metrics for every model you trained, and compare results\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eae97b-af7f-4d3a-a834-48ed7a400587",
   "metadata": {},
   "source": [
    "---\n",
    "Find out what each metric is telling us. Should we trust such high accuracies? Why is accuracy so high compared to the other metrics?\n",
    "\n",
    "YOUR ANSWER:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f8e9d-d0ef-40b4-945e-fa85507cb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO let's also do confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f403e-d4e8-4272-8e50-0807c4a9b21a",
   "metadata": {},
   "source": [
    "## Interpretability and explainability.\n",
    "\n",
    "### Cool, my models know stuff, but we also want to know! What do they look at when they predict toxicity? Is there a key feature?\n",
    "\n",
    "Model explainability is a critical component of machine learning that seeks to provide insights into how a model arrives at its predictions or decisions. In other words, it aims to make the \"black box\" of machine learning models more transparent, so that we can understand the factors that are driving the model's output.\n",
    "\n",
    "There are many different methods for achieving model explainability (more on this [here](https://www.kaggle.com/learn/machine-learning-explainability). These techniques can help us identify which features or variables are most important in driving the model's output, and can provide insights into the model's decision-making process.\n",
    "\n",
    "In this tutorial we'll explore ways of measuring feature importance, which will tell us what our models are looking out when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4918c-31a3-4827-81ea-d90935e0e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO explore feature importance\n",
    "# Do these features make sense?\n",
    "# Find out in moldred documentation what the features are and think why this is important for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c462e-0a0b-477c-a7a8-06ae6c613389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train another model (maybe XGBoost) and explain using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494863e8-5d37-4e6a-b4df-672e0ba3781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdd0b1-0584-4dbe-9dc4-7dd295e4042b",
   "metadata": {},
   "source": [
    "# Tasks for today: \n",
    "\n",
    "- scikit learn\n",
    "- classification\n",
    "- regression: [ESOL dataset](https://www.kaggle.com/competitions/MerckActivity/data)\n",
    "- XGBoost: [Merck kaggle challenge](https://www.kaggle.com/competitions/MerckActivity/data)\n",
    "- SHAP values + feature importance\n",
    "- Evaluation of ML models\n",
    "- Cross-validation: hyperparameter tuning\n",
    "- Train/valid/test split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4chem",
   "language": "python",
   "name": "ai4chem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1b1e114f4dae097b9e32029c5d22d73dc21a5dd723446d46774bd2adced9390"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
